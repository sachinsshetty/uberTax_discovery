version: '3.8'

services:
  vllm:
    image: vllm/vllm-openai:latest
    command: [
      "--model", "Qwen/Qwen3-VL-2B-Instruct-FP8",
      "--served-model-name", "gemma3",
      "--host", "0.0.0.0",
      "--port", "9000",
      "--gpu-memory-utilization", "0.9",
      "--tensor-parallel-size", "1",
      "--max-model-len", "8192",
      "--disable-log-requests",
      "--dtype", "bfloat16",
      "--enable-chunked-prefill",
      "--enable-prefix-caching",
      "--max-num-batched-tokens", "8192",
      "--chat-template-content-format", "openai",
      "--enable-auto-tool-choice",
      "--tool-call-parser", "hermes"
    ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - app-network
    restart: unless-stopped

  nginx:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./all-in-one-nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - vllm
      - tax_ui
      - server
    networks:
      - app-network
    restart: unless-stopped

  tax_ui:
    image: dwani/ubertax-ui
    expose:
      - "3000"
    environment:
      - VITE_DWANI_API_BASE_URL=http://server:18889  # Adjusted for internal Docker networking; change to external URL if needed
    networks:
      - app-network
    restart: unless-stopped

  server:
    image: dwani/ubertax-server:latest
    expose:
      - "18889"
    environment:
      - SQLITE_DB_PATH=/app/data/app.db
    volumes:
      - ./data:/app/data  # Optional: persist DB data; create ./data dir on host
    networks:
      - app-network
    restart: unless-stopped

networks:
  app-network:
    driver: bridge